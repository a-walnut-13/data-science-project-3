{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acf4e58-59a5-4be7-9b05-ed2f5dedb994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "# Base Model\n",
        "# mlp_baseline = MLPClassifier(hidden_layer_sizes=(100,),\n",
        "#                              activation='logistic',\n",
        "#                              solver='adam',\n",
        "#                              learning_rate_init=0.001, random_state=42,\n",
        "#                              verbose=True, early_stopping=True)\n",
        "\n",
        "# Test Model (two hidden layers)\n",
        "mlp_baseline = MLPClassifier(hidden_layer_sizes=(256, 128),\n",
        "                             activation='relu',\n",
        "                             learning_rate='adaptive',\n",
        "                             learning_rate_init=0.001,\n",
        "                             momentum=0.9,\n",
        "                             early_stopping=True,\n",
        "                             random_state=42,\n",
        "                             verbose=True)\n",
        "\n",
        "# Test Model (three hidden layers)\n",
        "# mlp_baseline = MLPClassifier(hidden_layer_sizes=(512, 256, 128),\n",
        "#                              activation='logistic',\n",
        "#                              solver='adam',\n",
        "#                              learning_rate_init=0.001,\n",
        "#                              early_stopping=True,\n",
        "#                              random_state=42,\n",
        "#                              verbose=True)\n",
        "\n",
        "start_time = time.time()\n",
        "mlp_baseline.fit(X_train, y_train)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "# Evaluate\n",
        "y_predict = mlp_baseline.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_predict)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "\n",
        "print(f\"Baseline Accuracy: {acc:.4f}\")\n",
        "print(f\"Training Time: {train_time:.2f} seconds\")\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1918fe78-60ff-4f4d-993c-37cb939910a7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.45783715\n",
            "Validation score: 0.872000\n",
            "Iteration 2, loss = 0.32062740\n",
            "Validation score: 0.875167\n",
            "Iteration 3, loss = 0.27955216\n",
            "Validation score: 0.877500\n",
            "Iteration 4, loss = 0.24878781\n",
            "Validation score: 0.882500\n",
            "Iteration 5, loss = 0.22653632\n",
            "Validation score: 0.888500\n",
            "Iteration 6, loss = 0.20629701\n",
            "Validation score: 0.890333\n",
            "Iteration 7, loss = 0.19099525\n",
            "Validation score: 0.887500\n",
            "Iteration 8, loss = 0.17115681\n",
            "Validation score: 0.887833\n",
            "Iteration 9, loss = 0.15745049\n",
            "Validation score: 0.892833\n",
            "Iteration 10, loss = 0.14635416\n",
            "Validation score: 0.887833\n",
            "Iteration 11, loss = 0.13654782\n",
            "Validation score: 0.891500\n",
            "Iteration 12, loss = 0.12984302\n",
            "Validation score: 0.892500\n",
            "Iteration 13, loss = 0.11400859\n",
            "Validation score: 0.892167\n",
            "Iteration 14, loss = 0.11108869\n",
            "Validation score: 0.897000\n",
            "Iteration 15, loss = 0.09853518\n",
            "Validation score: 0.885000\n",
            "Iteration 16, loss = 0.09247732\n",
            "Validation score: 0.890333\n",
            "Iteration 17, loss = 0.08379185\n",
            "Validation score: 0.885833\n",
            "Iteration 18, loss = 0.06991661\n",
            "Validation score: 0.890833\n",
            "Iteration 19, loss = 0.07244225\n",
            "Validation score: 0.886333\n",
            "Iteration 20, loss = 0.06663703\n",
            "Validation score: 0.892167\n",
            "Iteration 21, loss = 0.07479953\n",
            "Validation score: 0.893833\n",
            "Iteration 22, loss = 0.05852473\n",
            "Validation score: 0.890167\n",
            "Iteration 23, loss = 0.06263375\n",
            "Validation score: 0.892667\n",
            "Iteration 24, loss = 0.05100060\n",
            "Validation score: 0.893667\n",
            "Iteration 25, loss = 0.04192138\n",
            "Validation score: 0.893500\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Baseline Accuracy: 0.8894\n",
            "Training Time: 151.33 seconds\n",
            "Confusion Matrix:\n",
            " [[837   2  19  21   4   0 110   0   6   1]\n",
            " [  3 978   2  13   1   0   2   0   1   0]\n",
            " [ 15   1 837  14  76   1  56   0   0   0]\n",
            " [ 16   6   8 911  29   0  29   0   1   0]\n",
            " [  1   0 101  30 813   0  54   0   1   0]\n",
            " [  0   0   0   0   0 954   0  27   2  17]\n",
            " [125   1  91  28  73   0 676   0   6   0]\n",
            " [  0   0   0   0   0   8   0 958   1  33]\n",
            " [  6   1   6   9   2   6   7   3 960   0]\n",
            " [  0   0   0   0   0   9   1  20   0 970]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer Notes:\n",
        "---\n",
        "*   Baseline Model:\n",
        "Decent improvement. 50 iterations did not converge, Accuracy = .8808, Training Time = 117.15 seconds. With early stopping: Accuracy = .8832, Training Time = 58.39 seconds.\n",
        "*   Two Layers: Loss seemed to be converging at around 0.03 when 50 iterations completed, which took 306.88 seconds. Accuracy = .8832. Confusion matrix much better than in single layer case. With early stopping: Accuracy = .8894, Training Time = 130.20 seconds.\n",
        "*   Three Layers: Loss once again seemed to be converging around 0.03 after 50 iterations, which took 700.83 seconds (around 12 minutes). Accuracy = 0.8873. Confusion matrix nearing ideal. With early stopping: Accuracy = .8883, Training Time = 254.61 seconds. Overall, not significantly better than two layers for almost double runtime.\n",
        "---\n",
        "Notes on Activation Functions (Ran on Two-Layer w/ Early Stopping):\n",
        "---\n",
        "*   Relu: Accuracy = .8894, Training Time = 130.20 seconds\n",
        "*   Logistic: Accuracy = .8895, Training Time = 148.72 seconds\n",
        "*   Identity: Accuracy = .8381, Training Time = 116.75 seconds\n",
        "*   Tanh: Accuracy = .8854, Training Time = 213.36 seconds\n",
        "---\n",
        "Notes on Optimization Method (Two-Layer, Early Stopping, Relu)\n",
        "---\n",
        "*   ADAM: Accuracy = .8894, Training Time = 130.20 seconds\n",
        "*   SGD: Accuracy = .8828, Training Time = 347.90 seconds\n",
        "*   SGD w/ learning rate adjustments: Accuracy = .8894, Training Time = 151.33 seconds\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OGqFd8FJiihH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# your code here"
      ],
      "metadata": {
        "id": "0REsDBunNmEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}