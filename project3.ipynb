{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acf4e58-59a5-4be7-9b05-ed2f5dedb994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "# Base Model\n",
        "# mlp_baseline = MLPClassifier(hidden_layer_sizes=(100,),\n",
        "#                              activation='logistic',\n",
        "#                              solver='adam',\n",
        "#                              learning_rate_init=0.001, random_state=42,\n",
        "#                              verbose=True, early_stopping=True)\n",
        "\n",
        "# Test Model (two hidden layers)\n",
        "mlp_baseline = MLPClassifier(hidden_layer_sizes=(256, 128),\n",
        "                             activation='relu',\n",
        "                             learning_rate='adaptive',\n",
        "                             learning_rate_init=0.1,\n",
        "                             momentum=0.9,\n",
        "                             nesterovs_momentum=True,\n",
        "                             early_stopping=True,\n",
        "                             random_state=42,\n",
        "                             verbose=True)\n",
        "\n",
        "# Test Model (three hidden layers)\n",
        "# mlp_baseline = MLPClassifier(hidden_layer_sizes=(512, 256, 128),\n",
        "#                              activation='logistic',\n",
        "#                              solver='adam',\n",
        "#                              learning_rate_init=0.001,\n",
        "#                              early_stopping=True,\n",
        "#                              random_state=42,\n",
        "#                              verbose=True)\n",
        "\n",
        "start_time = time.time()\n",
        "mlp_baseline.fit(X_train, y_train)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "# Evaluate\n",
        "y_predict = mlp_baseline.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_predict)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "\n",
        "print(f\"Baseline Accuracy: {acc:.4f}\")\n",
        "print(f\"Training Time: {train_time:.2f} seconds\")\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709c2fcf-0e7c-4f54-f288-448b2a020f87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.54884967\n",
            "Validation score: 0.852833\n",
            "Iteration 2, loss = 0.39060186\n",
            "Validation score: 0.863167\n",
            "Iteration 3, loss = 0.37340545\n",
            "Validation score: 0.863833\n",
            "Iteration 4, loss = 0.34233881\n",
            "Validation score: 0.864000\n",
            "Iteration 5, loss = 0.34700316\n",
            "Validation score: 0.849000\n",
            "Iteration 6, loss = 0.33510961\n",
            "Validation score: 0.864333\n",
            "Iteration 7, loss = 0.30813687\n",
            "Validation score: 0.864167\n",
            "Iteration 8, loss = 0.31023136\n",
            "Validation score: 0.858500\n",
            "Iteration 9, loss = 0.31073046\n",
            "Validation score: 0.867833\n",
            "Iteration 10, loss = 0.31472638\n",
            "Validation score: 0.870000\n",
            "Iteration 11, loss = 0.29059168\n",
            "Validation score: 0.880500\n",
            "Iteration 12, loss = 0.30833237\n",
            "Validation score: 0.861000\n",
            "Iteration 13, loss = 0.31168481\n",
            "Validation score: 0.848500\n",
            "Iteration 14, loss = 0.29267140\n",
            "Validation score: 0.870833\n",
            "Iteration 15, loss = 0.29745978\n",
            "Validation score: 0.847000\n",
            "Iteration 16, loss = 0.29591638\n",
            "Validation score: 0.868167\n",
            "Iteration 17, loss = 0.27681090\n",
            "Validation score: 0.864333\n",
            "Iteration 18, loss = 0.27045400\n",
            "Validation score: 0.876333\n",
            "Iteration 19, loss = 0.29094867\n",
            "Validation score: 0.860000\n",
            "Iteration 20, loss = 0.29016831\n",
            "Validation score: 0.877000\n",
            "Iteration 21, loss = 0.29552542\n",
            "Validation score: 0.866167\n",
            "Iteration 22, loss = 0.29425418\n",
            "Validation score: 0.874500\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Baseline Accuracy: 0.8758\n",
            "Training Time: 135.73 seconds\n",
            "Confusion Matrix:\n",
            " [[864   1  12  15   2   0 100   0   6   0]\n",
            " [  4 972   0  16   2   0   5   0   1   0]\n",
            " [ 19   1 811  12  66   1  90   0   0   0]\n",
            " [ 37   9   7 876  38   1  29   0   3   0]\n",
            " [  0   0 108  27 795   0  67   1   2   0]\n",
            " [  0   0   0   0   0 972   2  18   4   4]\n",
            " [161   0  77  21  63   0 674   0   4   0]\n",
            " [  0   0   0   0   0  36   0 953   0  11]\n",
            " [  3   0   2   7   1   8  45   4 930   0]\n",
            " [  0   0   0   0   0  19   6  64   0 911]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer Notes:\n",
        "---\n",
        "*   Baseline Model:\n",
        "Decent improvement. 50 iterations did not converge, Accuracy = .8808, Training Time = 117.15 seconds. With early stopping: Accuracy = .8832, Training Time = 58.39 seconds.\n",
        "*   Two Layers: Loss seemed to be converging at around 0.03 when 50 iterations completed, which took 306.88 seconds. Accuracy = .8832. Confusion matrix much better than in single layer case. With early stopping: Accuracy = .8894, Training Time = 130.20 seconds.\n",
        "*   Three Layers: Loss once again seemed to be converging around 0.03 after 50 iterations, which took 700.83 seconds (around 12 minutes). Accuracy = 0.8873. Confusion matrix nearing ideal. With early stopping: Accuracy = .8883, Training Time = 254.61 seconds. Overall, not significantly better than two layers for almost double runtime.\n",
        "---\n",
        "Notes on Activation Functions (Ran on Two-Layer w/ Early Stopping):\n",
        "---\n",
        "*   Relu: Accuracy = .8894, Training Time = 130.20 seconds\n",
        "*   Logistic: Accuracy = .8895, Training Time = 148.72 seconds\n",
        "*   Identity: Accuracy = .8381, Training Time = 116.75 seconds\n",
        "*   Tanh: Accuracy = .8854, Training Time = 213.36 seconds\n",
        "---\n",
        "Notes on Optimization Method (Two-Layer, Early Stopping, Relu)\n",
        "---\n",
        "*   ADAM: Accuracy = .8894, Training Time = 130.20 seconds\n",
        "*   SGD: Accuracy = .8828, Training Time = 347.90 seconds\n",
        "*   SGD w/ learning rate adjustments: Accuracy = .8758, Training Time = 135.73 seconds\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OGqFd8FJiihH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# your code here"
      ],
      "metadata": {
        "id": "0REsDBunNmEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}